{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eccd398a-2a57-4bde-b071-c4d225251437",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pm4py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2555c843-0a3b-4422-8070-c6cea5ef7138",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import and preprocess data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pm4py\n",
    "import joblib\n",
    "\n",
    "#Enode Prefix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a047b2-61f9-41ba-ae50-f3af2c2275a3",
   "metadata": {},
   "source": [
    "1. Load data and keep necessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cb081d6-de03-41a7-a2f6-8be28da4cb7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>activity</th>\n",
       "      <th>case_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-13 08:40:25+00:00</td>\n",
       "      <td>assign seriousness</td>\n",
       "      <td>Case3608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-13 12:26:04+00:00</td>\n",
       "      <td>assign seriousness</td>\n",
       "      <td>Case2748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-13 12:30:37+00:00</td>\n",
       "      <td>assign seriousness</td>\n",
       "      <td>Case4284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-13 13:09:31+00:00</td>\n",
       "      <td>assign seriousness</td>\n",
       "      <td>Case1534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-13 17:25:25+00:00</td>\n",
       "      <td>assign seriousness</td>\n",
       "      <td>Case406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   timestamp            activity   case_id\n",
       "0  2010-01-13 08:40:25+00:00  assign seriousness  Case3608\n",
       "1  2010-01-13 12:26:04+00:00  assign seriousness  Case2748\n",
       "2  2010-01-13 12:30:37+00:00  assign seriousness  Case4284\n",
       "3  2010-01-13 13:09:31+00:00  assign seriousness  Case1534\n",
       "4  2010-01-13 17:25:25+00:00  assign seriousness   Case406"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_csv(\"bpi_df.csv\")\n",
    "#df = pd.read_csv(\"rmp_df.csv\")\n",
    "df = pd.read_csv('helpdesk_df.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "863f47d8-2235-4261-87d1-1a3b255464e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21221 entries, 0 to 21220\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   timestamp  21221 non-null  object\n",
      " 1   activity   21221 non-null  object\n",
      " 2   case_id    21221 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 497.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b0e7c5e-900c-46a7-8385-b70d4250e81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"]) # conversion from object to date type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5910d388-0e7d-4e11-b8bf-cb07547e8c0b",
   "metadata": {},
   "source": [
    "2. Split data into train-validation-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c5d1685-5276-49b5-a40c-2820b0f9999f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data test\n",
    "from split_train_test import split_train_test_temporal\n",
    "train, test, fp_dict = split_train_test_temporal(df,0.2,\"case_id\",\"timestamp\",\"preferred\")\n",
    "\n",
    "#split data validation\n",
    "train, val, fp_dict = split_train_test_temporal(train,0.1,\"case_id\",\"timestamp\",\"preferred\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50539c21-0e6b-4c68-bf08-c4e219d99a48",
   "metadata": {},
   "source": [
    "3. Add BOS and EOSÂ¶\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b12dae-08b6-4e8a-9e9d-f239a04ba23e",
   "metadata": {},
   "source": [
    "add bos and eos at the end of every case for prefix\n",
    "add eos at the end of every case for target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3950351e-98d3-4a59-ba2a-a3f8d9fd18dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bos_eos import add_bos_eos_target\n",
    "############## train data transformation ########################\n",
    "train_prefix = add_bos_eos_target(train,\"prefix\")\n",
    "train_target = add_bos_eos_target(train)\n",
    "\n",
    "############## validation data transformation ###################\n",
    "val_prefix = add_bos_eos_target(val,\"prefix\")\n",
    "val_target = add_bos_eos_target(val)\n",
    "\n",
    "############## test data transformation ########################\n",
    "test_prefix = add_bos_eos_target(test,\"prefix\")\n",
    "test_target = add_bos_eos_target(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1a22de-7c08-4b90-b162-b7ce77c141c9",
   "metadata": {},
   "source": [
    "4. Create Prefix Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c45e3d36-1dc1-468d-a367-51c32d3ec731",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prefix_trace import prefix_trace\n",
    "############## train data transformation ########################\n",
    "train_prefix_trace = prefix_trace(train_prefix)\n",
    "\n",
    "############## validation data transformation ###################\n",
    "val_prefix_trace = prefix_trace(val_prefix)\n",
    "\n",
    "############## test data transformation ########################\n",
    "test_prefix_trace = prefix_trace(test_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e473b444-7911-4aa0-8774-c9ea390ef373",
   "metadata": {},
   "source": [
    "5. Prefix Simple Index Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c608ae0f-a99c-406b-99b5-33a744767d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from encoding import find_max_len, si_encoding\n",
    "\n",
    "#all possible cases. I assume in a business all activities are already known and defined\n",
    "cases = df[\"activity\"].unique()\n",
    "cases = np.append(cases,\"BOS\")\n",
    "cases = np.append(cases,\"zos\")\n",
    "\n",
    "#find the maximum length of the longest case for padding\n",
    "max_len = find_max_len(train_prefix_trace[\"prefix\"],val_prefix_trace[\"prefix\"],test_prefix_trace[\"prefix\"])\n",
    "\n",
    "from encoding import si_encoding\n",
    "############## train data transformation ########################\n",
    "train_prefix_trace_encoded, label_encoder = si_encoding(train_prefix_trace,cases,max_len)\n",
    "train_target_encoded, a = si_encoding(train_target,cases,option = \"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a866054-b338-4ed1-a77b-d85736895a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "############## validation data transformation ###################\n",
    "val_prefix_trace_encoded, a = si_encoding(val_prefix_trace,cases,max_len)\n",
    "val_target_encoded, a = si_encoding(val_target,cases,option=\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e2c48e7-a557-4e89-924f-4f614dc95fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "############## test data transformation ########################\n",
    "test_prefix_trace_encoded, a = si_encoding(test_prefix_trace,cases,max_len)\n",
    "test_target_encoded, a = si_encoding(test_target,cases,option=\"target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bac38b-5660-4fb9-9c01-32cba6e941fb",
   "metadata": {},
   "source": [
    "6. Playout Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc55863b-e862-41fa-8afd-192a5e4a9212",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dfg_probabilities import dfg_df\n",
    "\n",
    "############ train #################\n",
    "#get probability\n",
    "train_prefix_copy = train_prefix.copy()\n",
    "probability = dfg_df(train_prefix,cases)\n",
    "\n",
    "#encode labels for probability index\n",
    "probability.index = label_encoder.transform(probability.index)\n",
    "probability.columns = label_encoder.transform(probability.columns)\n",
    "\n",
    "#reset index\n",
    "probability.reset_index(inplace=True)\n",
    "probability.rename(columns = {\"index\":\"activity\"},inplace=True)\n",
    "\n",
    "#encode drop extra columns and encode activity\n",
    "train_prefix[\"activity\"] = label_encoder.transform(train_prefix[\"activity\"])\n",
    "\n",
    "#merge to get new dataframe\n",
    "train_dfg_probability = pd.merge(train_prefix,probability,how=\"left\",on=\"activity\")\n",
    "train_dfg_probability = train_dfg_probability.drop(columns = [\"timestamp\",\"case_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "444c2698-6569-44fa-a477-1e6164142a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ validation ################################## \n",
    "#encode drop extra columns and encode activity\n",
    "val_prefix[\"activity\"] = label_encoder.transform(val_prefix[\"activity\"])\n",
    "\n",
    "#merge to get new dataframe. probability is same as train\n",
    "val_dfg_probability = pd.merge(val_prefix,probability,how=\"left\",on=\"activity\")\n",
    "val_dfg_probability = val_dfg_probability.drop(columns = [\"timestamp\",\"case_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6592ab1d-37a0-41e2-bf47-f6a4168973ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ test ################################## \n",
    "#probability is combination of train and validation\n",
    "train_val_prefix = pd.concat([train_prefix_copy,val_prefix])\n",
    "probability = dfg_df(train_val_prefix,cases)\n",
    "\n",
    "#encode drop extra columns and encode activity\n",
    "test_prefix[\"activity\"] = label_encoder.transform(test_prefix[\"activity\"])\n",
    "\n",
    "#encode labels for probability index\n",
    "probability.index = label_encoder.transform(probability.index)\n",
    "probability.columns = label_encoder.transform(probability.columns)\n",
    "\n",
    "#reset index\n",
    "probability.reset_index(inplace=True)\n",
    "probability.rename(columns = {\"index\":\"activity\"},inplace=True)\n",
    "\n",
    "#merge to get new dataframe\n",
    "test_dfg_probability = pd.merge(test_prefix,probability,how=\"left\",on=\"activity\")\n",
    "test_dfg_probability = test_dfg_probability.drop(columns = [\"timestamp\",\"case_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995b6b55-60a8-415e-954d-53a2ec9e44bd",
   "metadata": {},
   "source": [
    "Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1aa4d83b-6dc2-478c-8c0e-1792c11b3380",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################### Help Desk ###########################################################################\n",
    "\n",
    "##prefix data\n",
    "np.save(\"helpdesk_train_prefix.npy\",train_prefix_trace_encoded)\n",
    "np.save(\"helpdesk_val_prefix.npy\",val_prefix_trace_encoded)\n",
    "np.save(\"helpdesk_test_prefix.npy\",test_prefix_trace_encoded)\n",
    "\n",
    "##probability data\n",
    "train_dfg_probability.to_csv(\"helpdesk_train_dfg_probability.csv\",index=False)\n",
    "val_dfg_probability.to_csv(\"helpdesk_val_dfg_probability.csv\",index=False)\n",
    "test_dfg_probability.to_csv(\"helpdesk_test_dfg_probability.csv\",index=False)\n",
    "\n",
    "#target\n",
    "np.save(\"helpdesk_train_target.npy\",train_target_encoded)\n",
    "np.save(\"helpdesk_val_target.npy\",val_target_encoded)\n",
    "np.save(\"helpdesk_test_target.npy\",test_target_encoded)\n",
    "\n",
    "#original data\n",
    "train_target.to_csv(\"helpdesk_train_target_org.csv\",index=False)\n",
    "test_target.to_csv(\"helpdesk_test_target_org.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "180f417b-a538-4780-a25f-327d161a387a",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################### BPI Data ###############################################################################\n",
    "\n",
    "##prefix data\n",
    "np.save(\"bpi_train_prefix.npy\",train_prefix_trace_encoded)\n",
    "#np.save(\"bpi_val_prefix.npy\",val_prefix_trace_encoded)\n",
    "np.save(\"bpi_test_prefix.npy\",test_prefix_trace_encoded)\n",
    "\n",
    "##probability data\n",
    "train_dfg_probability.to_csv(\"bpi_train_dfg_probability.csv\",index=False)\n",
    "val_dfg_probability.to_csv(\"bpi_val_dfg_probability.csv\",index=False)\n",
    "test_dfg_probability.to_csv(\"bpi_test_dfg_probability.csv\",index=False)\n",
    "\n",
    "#target\n",
    "np.save(\"bpi_train_target.npy\",train_target_encoded)\n",
    "#np.save(\"bpi_val_target.npy\",val_target_encoded)\n",
    "np.save(\"bpi_test_target.npy\",test_target_encoded)\n",
    "\n",
    "#original data\n",
    "train_target.to_csv(\"bpi_train_target_org.csv\",index=False)\n",
    "test_target.to_csv(\"bpi_test_target_org.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3336d70b-9543-43e0-a6c4-983e644384b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################### RMP Data ###############################################################################\n",
    "\n",
    "##prefix data\n",
    "np.save(\"rmp_train_prefix.npy\",train_prefix_trace_encoded)\n",
    "np.save(\"rmp_val_prefix.npy\",val_prefix_trace_encoded)\n",
    "np.save(\"rmp_test_prefix.npy\",test_prefix_trace_encoded)\n",
    "\n",
    "##probability data\n",
    "train_dfg_probability.to_csv(\"rmp_train_dfg_probability.csv\",index=False)\n",
    "val_dfg_probability.to_csv(\"rmp_val_dfg_probability.csv\",index=False)\n",
    "test_dfg_probability.to_csv(\"rmp_test_dfg_probability.csv\",index=False)\n",
    "\n",
    "#target\n",
    "np.save(\"rmp_train_target.npy\",train_target_encoded)\n",
    "np.save(\"rmp_val_target.npy\",val_target_encoded)\n",
    "np.save(\"rmp_test_target.npy\",test_target_encoded)\n",
    "\n",
    "#original data\n",
    "train_target.to_csv(\"rmp_train_target_org.csv\",index=False)\n",
    "test_target.to_csv(\"rmp_test_target_org.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "739afdd2-dcd7-4ba8-9db4-cd7fb469fa94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['helpdesk_label_encoder.joblib']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Helpdesk \n",
    "joblib.dump(label_encoder, 'helpdesk_label_encoder.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909f5160-0782-4a0f-8fa9-7538e2b5a49a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
